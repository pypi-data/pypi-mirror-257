name: Whisper-Base
# id must match with the model dir name in qai_hub_models
id: whisper_asr
status: public
headline: Automatic speech recognition (ASR) model for multilingual
  transcription as well as translation.
domain: Audio
description: State-of-art model encoder-decoder transformer. The encoder takes
  an audio chunk (around 30 second) converted to a log-Mel spectrogram.  The
  decoder predicts the corresponding text caption intermixed with special tokens
  that can be used to direct the single model to perform various speech tasks.
use_case: Speech Recognition
tags:
  - foundation
research_paper: https://cdn.openai.com/papers/whisper.pdf
research_paper_title: Robust Speech Recognition via Large-Scale Weak Supervision
license: https://github.com/openai/whisper/blob/main/LICENSE
source_repo: https://github.com/openai/whisper/tree/main
technical_details:
  Encoder Number of parameters: 37.2M
  Decoder Number of parameters: 29.6M
  Model size: 270 MB
  Model checkpoint: Tiny En
  Input resolution: 80x3000
applicable_scenarios:
  - Smart Home
  - Accessibility
related_models:
  - huggingface_wavlm_base_plus
form_factors:
  - Phone
  - Tablet
  - IoT
has_static_banner: yes
has_animated_banner: yes
license_type: mit
dataset: []
