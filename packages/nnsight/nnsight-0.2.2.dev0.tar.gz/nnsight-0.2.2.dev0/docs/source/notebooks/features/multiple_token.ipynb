{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d129fe7-5a5f-441f-bb3f-288073f30c44",
   "metadata": {},
   "source": [
    "# Multiple Token Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39793d68-c96e-4069-82a3-31c283eb08eb",
   "metadata": {},
   "source": [
    "When generating more than one token, use `invoker.next()` to denote following interventions should be applied to the subsequent generations.\n",
    "\n",
    "Here we generate three tokens and save the hidden states of the last layer for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032125c8-3d90-4671-bd66-4cbbf090c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "model = LanguageModel('gpt2', device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48b0c3a-ac2d-4e5c-9dbf-cf1df44de0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "with model.generate(max_new_tokens=3) as generator:\n",
    "    with generator.invoke('The Eiffel Tower is in the city of') as invoker:\n",
    "\n",
    "        hidden_states1 = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "        invoker.next()\n",
    "        \n",
    "        hidden_states2 = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "        invoker.next()\n",
    "        \n",
    "        hidden_states3 = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "\n",
    "output = generator.output\n",
    "hidden_states1 = hidden_states1.value\n",
    "hidden_states2 = hidden_states2.value\n",
    "hidden_states3 = hidden_states3.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df3f8a-b8fd-4b9d-9f99-3bef39a7143f",
   "metadata": {},
   "source": [
    "Note how calling save *before* `invoker.next()` returns the hidden state across the initial prompt while calling save *after* returns the hidden state of each subsequent generated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea3a24a-773d-4305-a04d-2e964680c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([1, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states1.shape)\n",
    "print(hidden_states2.shape)\n",
    "print(hidden_states3.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
